````markdown
## Contiguous Tiled

Esta estrat√©gia ataca diretamente o problema de performance da vers√£o "naive": o acesso de mem√≥ria ruim √† Matriz B.

---

### 1. O Problema (Revis√£o)

O m√©todo "naive" (com loops `i, j, k`) tem um padr√£o de acesso p√©ssimo para a Matriz B:

* **Acesso √† Matriz A (`A[i][k]`):** `A[i][0]`, `A[i][1]`, `A[i][2]`...
    * ‚úî **Bom:** Acesso sequencial (horizontal), √≥timo para o cache.
* **Acesso √† Matriz B (`B[k][j]`):** `B[0][j]`, `B[1][j]`, `B[2][j]`...
    * üö® **P√©ssimo:** Acesso por coluna (vertical).
    * Se a matriz tem 1000 colunas, cada acesso (`B[0][j]`, `B[1][j]`) salta milhares de bytes na mem√≥ria, causando um "cache miss" constante. A CPU n√£o consegue prever ou otimizar isso.

---

### Tiling (Divis√£o em Blocos)

Em vez de processar a matriz inteira, n√≥s a quebramos em **blocos (tiles)** menores, de um tamanho `block_size` (ex: 16x16).



A ideia √© que **um bloco inteiro caiba confortavelmente no cache da CPU** (ex: L1 ou L2).

O c√≥digo implementa essa l√≥gica com 6 loops:

```rust
// Loops de BLOCO (externos)
let n = self.rows;
let m = self.cols;
let p = other.cols;
for ii in (0..n).step_by(block_size) {
    for jj in (0..p).step_by(block_size) {
        for kk in (0..m).step_by(block_size) {
            
            let i_max = (ii + block_size).min(n);
            let j_max = (jj + block_size).min(p);
            let k_max = (kk + block_size).min(m);
            // Loops de ELEMENTO (internos)
            // Processa um micro-bloco
            for i in ii..i_max {
                for j in jj..j_max {
                    let mut sum = result_data[i * p + j]; // Carrega o acumulado
                    for k in kk..k_max {
                        // Acesso √© igual ao naive, mas S√ì DENTRO DO BLOCO
                        sum += self.data[i * m + k] * other.data[k * p + j];
                    }
                    result_data[i * p + j] = sum; // Salva o acumulado
                }
            }
        }
    }
}
````

-----

### Por que isso √© R√°pido?

A m√°gica est√° no **reuso de dados** dentro do cache.

#### ‚úî Reuso do Bloco de Resultado (`result_data`)

  * O bloco `C[ii..i_max][jj..j_max]` √© selecionado pelos loops `ii` e `jj`.
  * Este bloco **permanece no cache** durante todo o loop `kk`.
  * Em vez de ler e escrever `C[i][j]` uma √∫nica vez (como no naive), n√≥s o lemos e escrevemos repetidamente (`block_size` vezes).
  * Isso √© chamado de **localidade temporal** (reusar dados que acabaram de ser usados).

#### ‚úî Reuso do Bloco da Matriz B (`other.data`)

  * Vamos analisar o loop `k` interno (`for k in kk..k_max`).
  * Ele ainda acessa a Matriz B verticalmente: `B[k][j]`.
  * **MAS...** ele s√≥ faz isso para `block_size` linhas (ex: 16 linhas), e n√£o `N` linhas (ex: 1000 linhas).
  * A CPU *consegue* carregar esses 16 pequenos peda√ßos de linhas no cache.
  * Quando o loop `i` interno (`for i in ii..i_max`) executa, ele **reutiliza** esses mesmos 16 peda√ßos de B que j√° est√£o no cache.

### Compara√ß√£o do Acesso √† Matriz B

| Vers√£o | Padr√£o de Acesso (`B[k][j]`) | Impacto no Cache |
| :--- | :--- | :--- |
| **Naive** | `B[0][j]`, `B[1][j]`, ... `B[1000][j]` | **Desastroso.** O cache n√£o consegue guardar 1000 linhas. |
| **Tiled** | `B[kk+0][j]`, `B[kk+1][j]`, ... `B[kk+15][j]` | **Excelente.** O cache guarda 16 linhas, que s√£o reutilizadas por todos os `i` do bloco. |

**Resumo:** O Tiling for√ßa o processador a trabalhar em sub-problemas pequenos o suficiente para caberem no cache. Ele troca um grande problema (com p√©ssimo acesso √† mem√≥ria) por milhares de pequenos problemas (com √≥timo acesso √† mem√≥ria).

```
```